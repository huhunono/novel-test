import pytest
import time
import random
import string
from tests.utils.assertions import assert_json_response,assert_ok_true

pytestmark = pytest.mark.regression.mark


LIST_PATH = "/book/listCommentByPage"
ADD_PATH  = "/book/addBookComment"

def _unique_comment(prefix="autotest")-> str:
    """
        Utility: Generate a globally unique string for test data identification.

        This function combines a custom prefix, a millisecond timestamp, and a random
        suffix to ensure that every comment or input generated during a test run
        is unique, preventing 'duplicate entry' errors in the database.

        Args:
            prefix (str): A label to identify the source of the data (default: "autotest").

        Returns:
            str: A unique string in the format: prefix-timestamp-random (e.g., "autotest-1706172000000-abc123").
        """
    ts=int(time.time()*1000)
    rnd="".join(random.choices(string.ascii_lowercase + string.digits, k=6))
    return f"{prefix}-{ts}-{rnd}"


def _pick_book_id_from_search(auth_http, base_url) -> str:
    """

    :param auth_http:
    :param base_url:
    :return:
        first book id in the search list
    """

    resp=auth_http.get(base_url + "/book/searchByPage",params={"pageNum": 1, "pageSize": 10}, allow_redirects=False)
    body=assert_json_response(resp)
    assert_ok_true(body)

    data = body.get("data")
    assert isinstance(data, dict), data
    items = data.get("list")
    assert isinstance(items, list) and items, data
    book_id = items[0].get("id")
    assert book_id is not None, items[0]
    return str(book_id)



def _extract_comment_list(body: dict):
    """
        Utility: Extract the raw list of comment objects from the response body.

        Args:
            body (dict): The parsed JSON response from the comment list endpoint.

        Returns:
            list: A list of comment dictionaries.

        Raises:
            AssertionError: If the 'data' or 'list' structure is missing or malformed.
    """
    data=body.get("data")
    assert data is not None, body

    if isinstance(data, dict) and "list" in data:
        return data.get("list")

    raise AssertionError(f"Cannot parse comment list from data: {data}")




def _find_comment_in_pages(auth_http, base_url, book_id: str, content: str,max_pages=5, page_size=20):
    """
        Utility: Search for a specific comment string across multiple pages.

        This implements a 'Search & Verify' pattern to account for eventual consistency
        or high-volume data where the target comment might not be on the first page.

        Args:
            auth_http: Authenticated Session object.
            base_url (str): The API base URL.
            book_id (str): The unique ID of the book.
            content (str): The unique string generated by _unique_comment().
            max_pages (int): Maximum depth of the paginated search.
            page_size (int): Number of items per request.

        Returns:
            tuple: (bool: found_status, dict: comment_object or None)
    """
    for page in range(1,max_pages+1):
        resp=auth_http.get(base_url+LIST_PATH, params={"bookId": book_id, "pageNum": page, "pageSize": page_size},allow_redirects=False)
        body=assert_json_response(resp)
        assert_ok_true(body)
        items=_extract_comment_list(body)

        for it in items:
            if isinstance(it,dict):
                text=it.get("commentContent")
                if text == content:
                    return True, it
    return False, None



def test_reg_comment_add_then_visible_in_list(auth_http, base_url):

    book_id = _pick_book_id_from_search(auth_http, base_url)
    content = _unique_comment()

    # 1) add comment

    resp_add = auth_http.post(base_url + ADD_PATH,
                              data={"bookId": book_id, "content": content},
                              allow_redirects=False)
    body_add = assert_json_response(resp_add)